"""
ğŸ“Š ĞĞ½Ğ°Ğ»Ğ¸Ñ‚Ğ¸ĞºĞ° | ĞšĞ¾Ğ½Ğ´Ğ¸Ñ‚ĞµÑ€ÑĞºĞ°Ñ ĞŸÑ€Ğ¾Ñ…Ğ¾Ñ€Ğ¾Ğ²Ğ°
Ğ”Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¸Ğ· 1Ğ¡:ĞšĞ¾Ğ¼Ğ¿Ğ»ĞµĞºÑĞ½Ğ°Ñ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ 2.5
"""

import streamlit as st
import psycopg2
import pandas as pd
import plotly.express as px
from datetime import datetime, timedelta


# ============================================================
# ĞĞĞ¡Ğ¢Ğ ĞĞ™ĞšĞ˜
# ============================================================

st.set_page_config(
    page_title="ĞĞ½Ğ°Ğ»Ğ¸Ñ‚Ğ¸ĞºĞ° | ĞšĞ¾Ğ½Ğ´Ğ¸Ñ‚ĞµÑ€ÑĞºĞ°Ñ ĞŸÑ€Ğ¾Ñ…Ğ¾Ñ€Ğ¾Ğ²Ğ°",
    page_icon="ğŸª",
    layout="wide",
    initial_sidebar_state="expanded"
)


# ============================================================
# ĞŸĞĞ”ĞšĞ›Ğ®Ğ§Ğ•ĞĞ˜Ğ• Ğš Ğ‘Ğ”
# ============================================================

@st.cache_resource
def get_connection():
    return psycopg2.connect(
        host=st.secrets["postgres"]["host"],
        port=st.secrets["postgres"]["port"],
        database=st.secrets["postgres"]["database"],
        user=st.secrets["postgres"]["user"],
        password=st.secrets["postgres"]["password"],
    )


# ============================================================
# Ğ—ĞĞŸĞ ĞĞ¡Ğ« Ğš Ğ‘Ğ”
# ============================================================

@st.cache_data(ttl=300)
def get_db_stats():
    """ĞĞ±Ñ‰Ğ°Ñ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ° Ğ¿Ğ¾ Ğ±Ğ°Ğ·Ğµ"""
    conn = get_connection()
    cur = conn.cursor()
    
    stats = {}
    
    cur.execute("SELECT COUNT(*), MIN(doc_date), MAX(doc_date), COALESCE(SUM(sum_total), 0) FROM purchase_prices")
    row = cur.fetchone()
    stats['purchases'] = {
        'count': row[0] or 0,
        'min_date': row[1],
        'max_date': row[2],
        'total_sum': float(row[3] or 0)
    }
    
    cur.execute("SELECT COUNT(*), MIN(doc_date), MAX(doc_date), COALESCE(SUM(sum_with_vat), 0) FROM sales")
    row = cur.fetchone()
    stats['sales'] = {
        'count': row[0] or 0,
        'min_date': row[1],
        'max_date': row[2],
        'total_sum': float(row[3] or 0)
    }
    
    cur.execute("SELECT COUNT(*) FROM nomenclature WHERE is_folder = false")
    stats['nomenclature_count'] = cur.fetchone()[0] or 0
    
    cur.execute("SELECT COUNT(*) FROM clients")
    stats['clients_count'] = cur.fetchone()[0] or 0
    
    cur.close()
    return stats


@st.cache_data(ttl=300)
def load_purchases(date_from: str, date_to: str):
    conn = get_connection()
    query = """
        SELECT 
            doc_date as "Ğ”Ğ°Ñ‚Ğ°",
            doc_number as "ĞĞ¾Ğ¼ĞµÑ€",
            contractor_name as "ĞŸĞ¾ÑÑ‚Ğ°Ğ²Ñ‰Ğ¸Ğº",
            nomenclature_name as "ĞĞ¾Ğ¼ĞµĞ½ĞºĞ»Ğ°Ñ‚ÑƒÑ€Ğ°",
            quantity as "ĞšĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾",
            price as "Ğ¦ĞµĞ½Ğ°",
            sum_total as "Ğ¡ÑƒĞ¼Ğ¼Ğ°"
        FROM purchase_prices
        WHERE doc_date BETWEEN %s AND %s
        ORDER BY doc_date DESC, nomenclature_name
    """
    return pd.read_sql(query, conn, params=[date_from, date_to])


@st.cache_data(ttl=300)
def get_purchases_analysis(date_from: str, date_to: str):
    conn = get_connection()
    query = """
        SELECT 
            nomenclature_name as "ĞĞ¾Ğ¼ĞµĞ½ĞºĞ»Ğ°Ñ‚ÑƒÑ€Ğ°",
            contractor_name as "ĞŸĞ¾ÑÑ‚Ğ°Ğ²Ñ‰Ğ¸Ğº",
            MIN(price) as "Ğ¦ĞµĞ½Ğ°_Ğ¼Ğ¸Ğ½",
            MAX(price) as "Ğ¦ĞµĞ½Ğ°_Ğ¼Ğ°ĞºÑ",
            ROUND(AVG(price)::numeric, 2) as "Ğ¦ĞµĞ½Ğ°_ÑÑ€ĞµĞ´Ğ½ÑÑ",
            (array_agg(price ORDER BY doc_date ASC))[1] as "Ğ¦ĞµĞ½Ğ°_Ğ¿ĞµÑ€Ğ²Ğ°Ñ",
            (array_agg(price ORDER BY doc_date DESC))[1] as "Ğ¦ĞµĞ½Ğ°_Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½ÑÑ",
            COUNT(*) as "ĞŸĞ¾ÑÑ‚Ğ°Ğ²Ğ¾Ğº",
            SUM(quantity) as "Ğ’ÑĞµĞ³Ğ¾_ĞºĞ¾Ğ»_Ğ²Ğ¾",
            SUM(sum_total) as "Ğ’ÑĞµĞ³Ğ¾_ÑÑƒĞ¼Ğ¼Ğ°",
            MIN(doc_date) as "ĞŸĞµÑ€Ğ²Ğ°Ñ_Ğ´Ğ°Ñ‚Ğ°",
            MAX(doc_date) as "ĞŸĞ¾ÑĞ»ĞµĞ´Ğ½ÑÑ_Ğ´Ğ°Ñ‚Ğ°"
        FROM purchase_prices
        WHERE doc_date BETWEEN %s AND %s
        GROUP BY nomenclature_name, contractor_name
        ORDER BY "Ğ’ÑĞµĞ³Ğ¾_ÑÑƒĞ¼Ğ¼Ğ°" DESC
    """
    df = pd.read_sql(query, conn, params=[date_from, date_to])
    
    if not df.empty:
        df["Ğ˜Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğµ_%"] = ((df["Ğ¦ĞµĞ½Ğ°_Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½ÑÑ"] - df["Ğ¦ĞµĞ½Ğ°_Ğ¿ĞµÑ€Ğ²Ğ°Ñ"]) / df["Ğ¦ĞµĞ½Ğ°_Ğ¿ĞµÑ€Ğ²Ğ°Ñ"] * 100).round(1)
        df["Ğ˜Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğµ_%"] = df["Ğ˜Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğµ_%"].replace([float('inf'), float('-inf')], 0).fillna(0)
    
    return df


@st.cache_data(ttl=300)
def load_sales(date_from: str, date_to: str):
    conn = get_connection()
    query = """
        SELECT 
            doc_type as "Ğ¢Ğ¸Ğ¿",
            doc_date as "Ğ”Ğ°Ñ‚Ğ°",
            doc_number as "ĞĞ¾Ğ¼ĞµÑ€",
            client_name as "ĞšĞ»Ğ¸ĞµĞ½Ñ‚",
            consignee_name as "Ğ“Ñ€ÑƒĞ·Ğ¾Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ°Ñ‚ĞµĞ»ÑŒ",
            nomenclature_name as "ĞĞ¾Ğ¼ĞµĞ½ĞºĞ»Ğ°Ñ‚ÑƒÑ€Ğ°",
            quantity as "ĞšĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾",
            price as "Ğ¦ĞµĞ½Ğ°",
            sum_with_vat as "Ğ¡ÑƒĞ¼Ğ¼Ğ°",
            pallets_count as "ĞŸĞ°Ğ»Ğ»ĞµÑ‚Ñ‹",
            logistics_cost_fact as "Ğ›Ğ¾Ğ³Ğ¸ÑÑ‚Ğ¸ĞºĞ°_Ñ„Ğ°ĞºÑ‚"
        FROM sales
        WHERE doc_date BETWEEN %s AND %s
        ORDER BY doc_date DESC
    """
    return pd.read_sql(query, conn, params=[date_from, date_to])


@st.cache_data(ttl=300)
def get_sales_by_client(date_from: str, date_to: str):
    conn = get_connection()
    query = """
        SELECT 
            client_name as "ĞšĞ»Ğ¸ĞµĞ½Ñ‚",
            SUM(quantity) as "ĞšĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾",
            SUM(sum_with_vat) as "Ğ¡ÑƒĞ¼Ğ¼Ğ°",
            COUNT(DISTINCT doc_number) as "Ğ”Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ²"
        FROM sales
        WHERE doc_date BETWEEN %s AND %s AND doc_type = 'Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ'
        GROUP BY client_name
        ORDER BY "Ğ¡ÑƒĞ¼Ğ¼Ğ°" DESC
    """
    return pd.read_sql(query, conn, params=[date_from, date_to])


@st.cache_data(ttl=300)
def get_sales_by_nomenclature(date_from: str, date_to: str):
    conn = get_connection()
    query = """
        SELECT 
            nomenclature_name as "ĞĞ¾Ğ¼ĞµĞ½ĞºĞ»Ğ°Ñ‚ÑƒÑ€Ğ°",
            SUM(quantity) as "ĞšĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾",
            SUM(sum_with_vat) as "Ğ¡ÑƒĞ¼Ğ¼Ğ°",
            COUNT(DISTINCT client_name) as "ĞšĞ»Ğ¸ĞµĞ½Ñ‚Ğ¾Ğ²"
        FROM sales
        WHERE doc_date BETWEEN %s AND %s AND doc_type = 'Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ'
        GROUP BY nomenclature_name
        ORDER BY "Ğ¡ÑƒĞ¼Ğ¼Ğ°" DESC
    """
    return pd.read_sql(query, conn, params=[date_from, date_to])


@st.cache_data(ttl=300)
def load_nomenclature_hierarchy():
    conn = get_connection()
    
    query_types = """
        WITH RECURSIVE type_tree AS (
            SELECT id, parent_id, name, is_folder, 0 as level, name as full_path
            FROM nomenclature_types WHERE parent_id IS NULL
            UNION ALL
            SELECT nt.id, nt.parent_id, nt.name, nt.is_folder, tt.level + 1,
                   tt.full_path || ' â†’ ' || nt.name
            FROM nomenclature_types nt
            JOIN type_tree tt ON nt.parent_id = tt.id
        )
        SELECT id, name, full_path, level, is_folder FROM type_tree ORDER BY full_path
    """
    types_df = pd.read_sql(query_types, conn)
    
    query_nom = """
        SELECT n.id, n.name as "ĞĞ°Ğ¸Ğ¼ĞµĞ½Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ", n.article as "ĞÑ€Ñ‚Ğ¸ĞºÑƒĞ»",
               n.code as "ĞšĞ¾Ğ´", n.type_id, n.weight as "Ğ’ĞµÑ"
        FROM nomenclature n WHERE n.is_folder = false ORDER BY n.name
    """
    nom_df = pd.read_sql(query_nom, conn)
    
    if not nom_df.empty and not types_df.empty:
        merged = nom_df.merge(types_df[['id', 'name', 'full_path']], 
                              left_on='type_id', right_on='id', how='left', suffixes=('', '_type'))
        merged = merged.rename(columns={'name': 'Ğ’Ğ¸Ğ´ Ğ½Ğ¾Ğ¼ĞµĞ½ĞºĞ»Ğ°Ñ‚ÑƒÑ€Ñ‹', 'full_path': 'Ğ˜ĞµÑ€Ğ°Ñ€Ñ…Ğ¸Ñ'})
        merged = merged[['Ğ˜ĞµÑ€Ğ°Ñ€Ñ…Ğ¸Ñ', 'Ğ’Ğ¸Ğ´ Ğ½Ğ¾Ğ¼ĞµĞ½ĞºĞ»Ğ°Ñ‚ÑƒÑ€Ñ‹', 'ĞĞ°Ğ¸Ğ¼ĞµĞ½Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ', 'ĞÑ€Ñ‚Ğ¸ĞºÑƒĞ»', 'ĞšĞ¾Ğ´', 'Ğ’ĞµÑ']]
        return merged.sort_values(['Ğ˜ĞµÑ€Ğ°Ñ€Ñ…Ğ¸Ñ', 'ĞĞ°Ğ¸Ğ¼ĞµĞ½Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ'])
    return nom_df


@st.cache_data(ttl=300)
def get_nomenclature_types_tree():
    conn = get_connection()
    query = """
        WITH RECURSIVE type_tree AS (
            SELECT id, parent_id, name, is_folder, 0 as level, name as path
            FROM nomenclature_types WHERE parent_id IS NULL
            UNION ALL
            SELECT nt.id, nt.parent_id, nt.name, nt.is_folder, tt.level + 1,
                   tt.path || ' â†’ ' || nt.name
            FROM nomenclature_types nt JOIN type_tree tt ON nt.parent_id = tt.id
        )
        SELECT path as "Ğ˜ĞµÑ€Ğ°Ñ€Ñ…Ğ¸Ñ", name as "ĞĞ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ğµ", 
               CASE WHEN is_folder THEN 'Ğ“Ñ€ÑƒĞ¿Ğ¿Ğ°' ELSE 'Ğ’Ğ¸Ğ´' END as "Ğ¢Ğ¸Ğ¿", level as "Ğ£Ñ€Ğ¾Ğ²ĞµĞ½ÑŒ"
        FROM type_tree ORDER BY path
    """
    return pd.read_sql(query, conn)


# ============================================================
# Ğ¡Ğ¢Ğ ĞĞĞ˜Ğ¦Ğ«
# ============================================================

def page_purchases(date_from, date_to):
    st.header("ğŸ›’ Ğ—Ğ°ĞºÑƒĞ¿ĞºĞ¸")
    st.caption("Ğ”Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ñ‹: ĞŸÑ€Ğ¸Ğ¾Ğ±Ñ€ĞµÑ‚ĞµĞ½Ğ¸Ğµ Ñ‚Ğ¾Ğ²Ğ°Ñ€Ğ¾Ğ² Ğ¸ ÑƒÑĞ»ÑƒĞ³ (ĞŸÑ€Ğ¾Ğ²ĞµĞ´Ñ‘Ğ½Ğ½Ñ‹Ğµ)")
    
    df = load_purchases(str(date_from), str(date_to))
    analysis_df = get_purchases_analysis(str(date_from), str(date_to))
    
    if df.empty:
        st.warning("ĞĞµÑ‚ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¾ Ğ·Ğ°ĞºÑƒĞ¿ĞºĞ°Ñ… Ğ·Ğ° Ğ²Ñ‹Ğ±Ñ€Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ğ¿ĞµÑ€Ğ¸Ğ¾Ğ´")
        return
    
    # ========== ĞœĞ•Ğ¢Ğ Ğ˜ĞšĞ˜ ==========
    st.subheader("ğŸ“ˆ Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ° Ğ·Ğ° Ğ¿ĞµÑ€Ğ¸Ğ¾Ğ´")
    col1, col2, col3, col4 = st.columns(4)
    col1.metric("Ğ—Ğ°Ğ¿Ğ¸ÑĞµĞ¹", f"{len(df):,}")
    col2.metric("ĞŸĞ¾ÑÑ‚Ğ°Ğ²Ñ‰Ğ¸ĞºĞ¾Ğ²", df['ĞŸĞ¾ÑÑ‚Ğ°Ğ²Ñ‰Ğ¸Ğº'].nunique())
    col3.metric("ĞŸĞ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¹", df['ĞĞ¾Ğ¼ĞµĞ½ĞºĞ»Ğ°Ñ‚ÑƒÑ€Ğ°'].nunique())
    col4.metric("Ğ¡ÑƒĞ¼Ğ¼Ğ° Ğ·Ğ°ĞºÑƒĞ¿Ğ¾Ğº", f"{df['Ğ¡ÑƒĞ¼Ğ¼Ğ°'].sum():,.0f} â‚½")
    
    # ========== Ğ¤Ğ˜Ğ›Ğ¬Ğ¢Ğ Ğ« ==========
    st.subheader("ğŸ” Ğ¤Ğ¸Ğ»ÑŒÑ‚Ñ€Ñ‹")
    col1, col2 = st.columns(2)
    with col1:
        suppliers = ['Ğ’ÑĞµ'] + sorted(df['ĞŸĞ¾ÑÑ‚Ğ°Ğ²Ñ‰Ğ¸Ğº'].dropna().unique().tolist())
        selected_supplier = st.selectbox("ĞŸĞ¾ÑÑ‚Ğ°Ğ²Ñ‰Ğ¸Ğº", suppliers, key="purch_supplier")
    with col2:
        search_text = st.text_input("ĞŸĞ¾Ğ¸ÑĞº Ğ¿Ğ¾ Ğ½Ğ¾Ğ¼ĞµĞ½ĞºĞ»Ğ°Ñ‚ÑƒÑ€Ğµ", "", key="purch_search")
    
    # ĞŸÑ€Ğ¸Ğ¼ĞµĞ½ÑĞµĞ¼ Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ñ‹
    filtered_df = df.copy()
    filtered_analysis = analysis_df.copy()
    
    if selected_supplier != 'Ğ’ÑĞµ':
        filtered_df = filtered_df[filtered_df['ĞŸĞ¾ÑÑ‚Ğ°Ğ²Ñ‰Ğ¸Ğº'] == selected_supplier]
        filtered_analysis = filtered_analysis[filtered_analysis['ĞŸĞ¾ÑÑ‚Ğ°Ğ²Ñ‰Ğ¸Ğº'] == selected_supplier]
    
    if search_text:
        mask = filtered_df['ĞĞ¾Ğ¼ĞµĞ½ĞºĞ»Ğ°Ñ‚ÑƒÑ€Ğ°'].str.lower().str.contains(search_text.lower(), na=False)
        filtered_df = filtered_df[mask]
        mask_analysis = filtered_analysis['ĞĞ¾Ğ¼ĞµĞ½ĞºĞ»Ğ°Ñ‚ÑƒÑ€Ğ°'].str.lower().str.contains(search_text.lower(), na=False)
        filtered_analysis = filtered_analysis[mask_analysis]
    
    # ========== Ğ’ĞšĞ›ĞĞ”ĞšĞ˜ ==========
    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“‹ Ğ’ÑĞµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ", "ğŸ“Š ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ñ†ĞµĞ½", "ğŸ“ˆ Ğ”Ğ¸Ğ½Ğ°Ğ¼Ğ¸ĞºĞ°", "ğŸ† Ğ¢Ğ¾Ğ¿ Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğ¹"])
    
    with tab1:
        st.subheader(f"Ğ”Ğ°Ğ½Ğ½Ñ‹Ğµ ({len(filtered_df)} Ğ·Ğ°Ğ¿Ğ¸ÑĞµĞ¹)")
        st.dataframe(
            filtered_df,
            use_container_width=True,
            hide_index=True,
            column_config={
                "Ğ”Ğ°Ñ‚Ğ°": st.column_config.DateColumn("Ğ”Ğ°Ñ‚Ğ°", format="DD.MM.YYYY"),
                "Ğ¦ĞµĞ½Ğ°": st.column_config.NumberColumn("Ğ¦ĞµĞ½Ğ°", format="%.2f â‚½"),
                "Ğ¡ÑƒĞ¼Ğ¼Ğ°": st.column_config.NumberColumn("Ğ¡ÑƒĞ¼Ğ¼Ğ°", format="%.2f â‚½"),
            }
        )
        csv = filtered_df.to_csv(index=False).encode('utf-8-sig')
        st.download_button("ğŸ“¥ Ğ¡ĞºĞ°Ñ‡Ğ°Ñ‚ÑŒ CSV", csv, "Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ñ_Ñ†ĞµĞ½.csv", "text/csv")
    
    with tab2:
        st.subheader("ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ¿Ğ¾ Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸ÑĞ¼")
        if not filtered_analysis.empty:
            st.dataframe(
                filtered_analysis,
                use_container_width=True,
                hide_index=True,
                column_config={
                    "Ğ¦ĞµĞ½Ğ°_Ğ¼Ğ¸Ğ½": st.column_config.NumberColumn("ĞœĞ¸Ğ½", format="%.2f â‚½"),
                    "Ğ¦ĞµĞ½Ğ°_Ğ¼Ğ°ĞºÑ": st.column_config.NumberColumn("ĞœĞ°ĞºÑ", format="%.2f â‚½"),
                    "Ğ¦ĞµĞ½Ğ°_ÑÑ€ĞµĞ´Ğ½ÑÑ": st.column_config.NumberColumn("Ğ¡Ñ€ĞµĞ´Ğ½ÑÑ", format="%.2f â‚½"),
                    "Ğ¦ĞµĞ½Ğ°_Ğ¿ĞµÑ€Ğ²Ğ°Ñ": st.column_config.NumberColumn("ĞŸĞµÑ€Ğ²Ğ°Ñ", format="%.2f â‚½"),
                    "Ğ¦ĞµĞ½Ğ°_Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½ÑÑ": st.column_config.NumberColumn("ĞŸĞ¾ÑĞ»ĞµĞ´Ğ½ÑÑ", format="%.2f â‚½"),
                    "Ğ˜Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğµ_%": st.column_config.NumberColumn("Ğ˜Ğ·Ğ¼. %", format="%.1f%%"),
                    "Ğ’ÑĞµĞ³Ğ¾_ÑÑƒĞ¼Ğ¼Ğ°": st.column_config.NumberColumn("Ğ¡ÑƒĞ¼Ğ¼Ğ°", format="%.0f â‚½"),
                }
            )
    
    with tab3:
        st.subheader("Ğ”Ğ¸Ğ½Ğ°Ğ¼Ğ¸ĞºĞ° Ñ†ĞµĞ½Ñ‹")
        nomenclatures = sorted(filtered_df['ĞĞ¾Ğ¼ĞµĞ½ĞºĞ»Ğ°Ñ‚ÑƒÑ€Ğ°'].unique().tolist())
        
        if nomenclatures:
            selected_nom = st.selectbox("Ğ’Ñ‹Ğ±ĞµÑ€Ğ¸Ñ‚Ğµ Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ñ", nomenclatures, key="purch_nom")
            
            if selected_nom:
                nom_df = filtered_df[filtered_df['ĞĞ¾Ğ¼ĞµĞ½ĞºĞ»Ğ°Ñ‚ÑƒÑ€Ğ°'] == selected_nom].copy()
                
                if len(nom_df) > 1:
                    fig = px.line(
                        nom_df,
                        x='Ğ”Ğ°Ñ‚Ğ°',
                        y='Ğ¦ĞµĞ½Ğ°',
                        color='ĞŸĞ¾ÑÑ‚Ğ°Ğ²Ñ‰Ğ¸Ğº',
                        markers=True,
                        title=f"Ğ”Ğ¸Ğ½Ğ°Ğ¼Ğ¸ĞºĞ° Ñ†ĞµĞ½Ñ‹: {selected_nom}"
                    )
                    fig.update_layout(
                        xaxis_title="Ğ”Ğ°Ñ‚Ğ°",
                        yaxis_title="Ğ¦ĞµĞ½Ğ°, â‚½",
                        hovermode='x unified'
                    )
                    st.plotly_chart(fig, use_container_width=True)
                    
                    col1, col2, col3 = st.columns(3)
                    col1.metric("ĞœĞ¸Ğ½. Ñ†ĞµĞ½Ğ°", f"{nom_df['Ğ¦ĞµĞ½Ğ°'].min():.2f} â‚½")
                    col2.metric("ĞœĞ°ĞºÑ. Ñ†ĞµĞ½Ğ°", f"{nom_df['Ğ¦ĞµĞ½Ğ°'].max():.2f} â‚½")
                    first_price = nom_df.sort_values('Ğ”Ğ°Ñ‚Ğ°')['Ğ¦ĞµĞ½Ğ°'].iloc[0]
                    last_price = nom_df.sort_values('Ğ”Ğ°Ñ‚Ğ°')['Ğ¦ĞµĞ½Ğ°'].iloc[-1]
                    change = last_price - first_price
                    col3.metric("Ğ˜Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğµ", f"{last_price:.2f} â‚½", f"{change:+.2f} â‚½")
                else:
                    st.info("ĞĞµĞ´Ğ¾ÑÑ‚Ğ°Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ»Ñ Ğ³Ñ€Ğ°Ñ„Ğ¸ĞºĞ° (Ğ½ÑƒĞ¶Ğ½Ğ¾ Ğ¼Ğ¸Ğ½Ğ¸Ğ¼ÑƒĞ¼ 2 Ğ·Ğ°Ğ¿Ğ¸ÑĞ¸)")
    
    with tab4:
        if not filtered_analysis.empty:
            multi = filtered_analysis[filtered_analysis['ĞŸĞ¾ÑÑ‚Ğ°Ğ²Ğ¾Ğº'] > 1].copy()
            
            if not multi.empty:
                col1, col2 = st.columns(2)
                with col1:
                    st.subheader("ğŸ“ˆ Ğ¢Ğ¾Ğ¿ Ğ¿Ğ¾ Ñ€Ğ¾ÑÑ‚Ñƒ Ñ†ĞµĞ½Ñ‹")
                    top_growth = multi.nlargest(10, 'Ğ˜Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğµ_%')[
                        ['ĞĞ¾Ğ¼ĞµĞ½ĞºĞ»Ğ°Ñ‚ÑƒÑ€Ğ°', 'ĞŸĞ¾ÑÑ‚Ğ°Ğ²Ñ‰Ğ¸Ğº', 'Ğ¦ĞµĞ½Ğ°_Ğ¿ĞµÑ€Ğ²Ğ°Ñ', 'Ğ¦ĞµĞ½Ğ°_Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½ÑÑ', 'Ğ˜Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğµ_%']
                    ]
                    st.dataframe(top_growth, hide_index=True, use_container_width=True)
                
                with col2:
                    st.subheader("ğŸ“‰ Ğ¢Ğ¾Ğ¿ Ğ¿Ğ¾ ÑĞ½Ğ¸Ğ¶ĞµĞ½Ğ¸Ñ Ñ†ĞµĞ½Ñ‹")
                    top_decline = multi.nsmallest(10, 'Ğ˜Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğµ_%')[
                        ['ĞĞ¾Ğ¼ĞµĞ½ĞºĞ»Ğ°Ñ‚ÑƒÑ€Ğ°', 'ĞŸĞ¾ÑÑ‚Ğ°Ğ²Ñ‰Ğ¸Ğº', 'Ğ¦ĞµĞ½Ğ°_Ğ¿ĞµÑ€Ğ²Ğ°Ñ', 'Ğ¦ĞµĞ½Ğ°_Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½ÑÑ', 'Ğ˜Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğµ_%']
                    ]
                    st.dataframe(top_decline, hide_index=True, use_container_width=True)
                
                st.subheader("Ğ Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğ¹ Ñ†ĞµĞ½")
                fig = px.histogram(multi, x='Ğ˜Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğµ_%', nbins=30, title="Ğ Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğ¹ Ñ†ĞµĞ½ (%)")
                fig.add_vline(x=0, line_dash="dash", line_color="red")
                st.plotly_chart(fig, use_container_width=True)
            else:
                st.info("ĞĞµĞ´Ğ¾ÑÑ‚Ğ°Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ»Ñ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° (Ğ½ÑƒĞ¶Ğ½Ñ‹ Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¸ Ñ 2+ Ğ¿Ğ¾ÑÑ‚Ğ°Ğ²ĞºĞ°Ğ¼Ğ¸)")


def page_sales(date_from, date_to):
    st.header("ğŸ’° ĞŸÑ€Ğ¾Ğ´Ğ°Ğ¶Ğ¸")
    st.caption("Ğ”Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ñ‹: Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ñ‚Ğ¾Ğ²Ğ°Ñ€Ğ¾Ğ² Ğ¸ ÑƒÑĞ»ÑƒĞ³ + ĞšĞ¾Ñ€Ñ€ĞµĞºÑ‚Ğ¸Ñ€Ğ¾Ğ²ĞºĞ¸ (ĞŸÑ€Ğ¾Ğ²ĞµĞ´Ñ‘Ğ½Ğ½Ñ‹Ğµ)")
    
    df = load_sales(str(date_from), str(date_to))
    
    if df.empty:
        st.warning("ĞĞµÑ‚ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¾ Ğ¿Ñ€Ğ¾Ğ´Ğ°Ğ¶Ğ°Ñ… Ğ·Ğ° Ğ²Ñ‹Ğ±Ñ€Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ğ¿ĞµÑ€Ğ¸Ğ¾Ğ´")
        return
    
    realizations = df[df['Ğ¢Ğ¸Ğ¿'] == 'Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ']
    corrections = df[df['Ğ¢Ğ¸Ğ¿'] == 'ĞšĞ¾Ñ€Ñ€ĞµĞºÑ‚Ğ¸Ñ€Ğ¾Ğ²ĞºĞ°']
    
    col1, col2, col3, col4 = st.columns(4)
    col1.metric("Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¹", f"{len(realizations):,}")
    col2.metric("ĞšĞ¾Ñ€Ñ€ĞµĞºÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ¾Ğº", f"{len(corrections):,}")
    col3.metric("ĞšĞ»Ğ¸ĞµĞ½Ñ‚Ğ¾Ğ²", df['ĞšĞ»Ğ¸ĞµĞ½Ñ‚'].nunique())
    col4.metric("Ğ’Ñ‹Ñ€ÑƒÑ‡ĞºĞ°", f"{realizations['Ğ¡ÑƒĞ¼Ğ¼Ğ°'].sum():,.0f} â‚½")
    
    col1, col2, col3 = st.columns(3)
    col1.metric("ĞŸĞ°Ğ»Ğ»ĞµÑ‚", f"{realizations['ĞŸĞ°Ğ»Ğ»ĞµÑ‚Ñ‹'].sum():,.0f}")
    col2.metric("Ğ›Ğ¾Ğ³Ğ¸ÑÑ‚Ğ¸ĞºĞ° (Ñ„Ğ°ĞºÑ‚)", f"{realizations['Ğ›Ğ¾Ğ³Ğ¸ÑÑ‚Ğ¸ĞºĞ°_Ñ„Ğ°ĞºÑ‚'].sum():,.0f} â‚½")
    col3.metric("Ğ¡ÑƒĞ¼Ğ¼Ğ° ĞºĞ¾Ñ€Ñ€ĞµĞºÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ¾Ğº", f"{corrections['Ğ¡ÑƒĞ¼Ğ¼Ğ°'].sum():,.0f} â‚½")
    
    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“‹ Ğ’ÑĞµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ", "ğŸ‘¥ ĞŸĞ¾ ĞºĞ»Ğ¸ĞµĞ½Ñ‚Ğ°Ğ¼", "ğŸ“¦ ĞŸĞ¾ Ğ½Ğ¾Ğ¼ĞµĞ½ĞºĞ»Ğ°Ñ‚ÑƒÑ€Ğµ", "ğŸšš ĞŸĞ¾ Ğ³Ñ€ÑƒĞ·Ğ¾Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ°Ñ‚ĞµĞ»ÑĞ¼"])
    
    with tab1:
        col1, col2, col3 = st.columns(3)
        with col1:
            doc_type = st.selectbox("Ğ¢Ğ¸Ğ¿ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°", ['Ğ’ÑĞµ', 'Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ', 'ĞšĞ¾Ñ€Ñ€ĞµĞºÑ‚Ğ¸Ñ€Ğ¾Ğ²ĞºĞ°'], key="sales_type")
        with col2:
            clients = ['Ğ’ÑĞµ'] + sorted(df['ĞšĞ»Ğ¸ĞµĞ½Ñ‚'].dropna().unique().tolist())
            client = st.selectbox("ĞšĞ»Ğ¸ĞµĞ½Ñ‚", clients, key="sales_client")
        with col3:
            search = st.text_input("ĞŸĞ¾Ğ¸ÑĞº Ğ¿Ğ¾ Ğ½Ğ¾Ğ¼ĞµĞ½ĞºĞ»Ğ°Ñ‚ÑƒÑ€Ğµ", key="sales_search")
        
        filtered = df.copy()
        if doc_type != 'Ğ’ÑĞµ':
            filtered = filtered[filtered['Ğ¢Ğ¸Ğ¿'] == doc_type]
        if client != 'Ğ’ÑĞµ':
            filtered = filtered[filtered['ĞšĞ»Ğ¸ĞµĞ½Ñ‚'] == client]
        if search:
            filtered = filtered[filtered['ĞĞ¾Ğ¼ĞµĞ½ĞºĞ»Ğ°Ñ‚ÑƒÑ€Ğ°'].str.lower().str.contains(search.lower(), na=False)]
        
        st.dataframe(filtered, use_container_width=True, hide_index=True)
        csv = filtered.to_csv(index=False).encode('utf-8-sig')
        st.download_button("ğŸ“¥ Ğ¡ĞºĞ°Ñ‡Ğ°Ñ‚ÑŒ CSV", csv, "Ğ¿Ñ€Ğ¾Ğ´Ğ°Ğ¶Ğ¸.csv", "text/csv")
    
    with tab2:
        by_client = get_sales_by_client(str(date_from), str(date_to))
        if not by_client.empty:
            col1, col2 = st.columns([2, 1])
            with col1:
                st.dataframe(by_client, use_container_width=True, hide_index=True)
            with col2:
                top10 = by_client.head(10)
                if not top10.empty:
                    fig = px.pie(top10, values='Ğ¡ÑƒĞ¼Ğ¼Ğ°', names='ĞšĞ»Ğ¸ĞµĞ½Ñ‚', title='Ğ¢Ğ¾Ğ¿-10 ĞºĞ»Ğ¸ĞµĞ½Ñ‚Ğ¾Ğ²')
                    st.plotly_chart(fig, use_container_width=True)
    
    with tab3:
        by_nom = get_sales_by_nomenclature(str(date_from), str(date_to))
        if not by_nom.empty:
            col1, col2 = st.columns([2, 1])
            with col1:
                st.dataframe(by_nom, use_container_width=True, hide_index=True)
            with col2:
                top10 = by_nom.head(10)
                if not top10.empty:
                    fig = px.bar(top10, x='Ğ¡ÑƒĞ¼Ğ¼Ğ°', y='ĞĞ¾Ğ¼ĞµĞ½ĞºĞ»Ğ°Ñ‚ÑƒÑ€Ğ°', orientation='h', title='Ğ¢Ğ¾Ğ¿-10 Ñ‚Ğ¾Ğ²Ğ°Ñ€Ğ¾Ğ²')
                    fig.update_layout(yaxis={'categoryorder':'total ascending'})
                    st.plotly_chart(fig, use_container_width=True)
    
    with tab4:
        by_consignee = realizations.groupby('Ğ“Ñ€ÑƒĞ·Ğ¾Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ°Ñ‚ĞµĞ»ÑŒ').agg({
            'ĞšĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾': 'sum', 'Ğ¡ÑƒĞ¼Ğ¼Ğ°': 'sum', 'ĞŸĞ°Ğ»Ğ»ĞµÑ‚Ñ‹': 'sum', 'Ğ›Ğ¾Ğ³Ğ¸ÑÑ‚Ğ¸ĞºĞ°_Ñ„Ğ°ĞºÑ‚': 'sum'
        }).reset_index().sort_values('Ğ¡ÑƒĞ¼Ğ¼Ğ°', ascending=False)
        st.dataframe(by_consignee, use_container_width=True, hide_index=True)


def page_nomenclature():
    st.header("ğŸ“¦ ĞĞ¾Ğ¼ĞµĞ½ĞºĞ»Ğ°Ñ‚ÑƒÑ€Ğ°")
    
    tab1, tab2 = st.tabs(["ğŸ“‹ Ğ¡Ğ¿Ñ€Ğ°Ğ²Ğ¾Ñ‡Ğ½Ğ¸Ğº", "ğŸŒ³ Ğ¡Ñ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ° Ğ²Ğ¸Ğ´Ğ¾Ğ²"])
    
    with tab1:
        df = load_nomenclature_hierarchy()
        if df.empty:
            st.warning("Ğ¡Ğ¿Ñ€Ğ°Ğ²Ğ¾Ñ‡Ğ½Ğ¸Ğº Ğ½Ğ¾Ğ¼ĞµĞ½ĞºĞ»Ğ°Ñ‚ÑƒÑ€Ñ‹ Ğ¿ÑƒÑÑ‚")
            return
        
        col1, col2 = st.columns(2)
        col1.metric("Ğ’ÑĞµĞ³Ğ¾ Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¹", f"{len(df):,}")
        col2.metric("Ğ’Ğ¸Ğ´Ğ¾Ğ² Ğ½Ğ¾Ğ¼ĞµĞ½ĞºĞ»Ğ°Ñ‚ÑƒÑ€Ñ‹", df['Ğ’Ğ¸Ğ´ Ğ½Ğ¾Ğ¼ĞµĞ½ĞºĞ»Ğ°Ñ‚ÑƒÑ€Ñ‹'].nunique())
        
        col1, col2 = st.columns(2)
        with col1:
            hierarchies = ['Ğ’ÑĞµ'] + sorted(df['Ğ˜ĞµÑ€Ğ°Ñ€Ñ…Ğ¸Ñ'].dropna().unique().tolist())
            hierarchy = st.selectbox("Ğ“Ñ€ÑƒĞ¿Ğ¿Ğ° / Ğ’Ğ¸Ğ´ Ğ½Ğ¾Ğ¼ĞµĞ½ĞºĞ»Ğ°Ñ‚ÑƒÑ€Ñ‹", hierarchies)
        with col2:
            search = st.text_input("ĞŸĞ¾Ğ¸ÑĞº", key="nom_search")
        
        filtered = df.copy()
        if hierarchy != 'Ğ’ÑĞµ':
            filtered = filtered[filtered['Ğ˜ĞµÑ€Ğ°Ñ€Ñ…Ğ¸Ñ'] == hierarchy]
        if search:
            mask = (filtered['ĞĞ°Ğ¸Ğ¼ĞµĞ½Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ'].str.lower().str.contains(search.lower(), na=False) |
                    filtered['ĞÑ€Ñ‚Ğ¸ĞºÑƒĞ»'].fillna('').str.lower().str.contains(search.lower(), na=False))
            filtered = filtered[mask]
        
        st.dataframe(filtered, use_container_width=True, hide_index=True)
        
        st.subheader("Ğ Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ Ğ¿Ğ¾ Ğ²Ğ¸Ğ´Ğ°Ğ¼")
        by_type = df.groupby('Ğ’Ğ¸Ğ´ Ğ½Ğ¾Ğ¼ĞµĞ½ĞºĞ»Ğ°Ñ‚ÑƒÑ€Ñ‹').size().reset_index(name='ĞšĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾').sort_values('ĞšĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾', ascending=False)
        fig = px.bar(by_type.head(15), x='Ğ’Ğ¸Ğ´ Ğ½Ğ¾Ğ¼ĞµĞ½ĞºĞ»Ğ°Ñ‚ÑƒÑ€Ñ‹', y='ĞšĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾', title='Ğ¢Ğ¾Ğ¿-15 Ğ²Ğ¸Ğ´Ğ¾Ğ²')
        st.plotly_chart(fig, use_container_width=True)
    
    with tab2:
        st.subheader("Ğ¡Ñ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ° Ğ²Ğ¸Ğ´Ğ¾Ğ² Ğ½Ğ¾Ğ¼ĞµĞ½ĞºĞ»Ğ°Ñ‚ÑƒÑ€Ñ‹")
        tree = get_nomenclature_types_tree()
        if not tree.empty:
            st.dataframe(tree, use_container_width=True, hide_index=True)


def page_summary(date_from, date_to):
    st.header("ğŸ“ˆ Ğ¡Ğ²Ğ¾Ğ´ĞºĞ°")
    
    stats = get_db_stats()
    
    col1, col2, col3, col4 = st.columns(4)
    col1.metric("Ğ—Ğ°ĞºÑƒĞ¿ĞºĞ¸", f"{stats['purchases']['count']:,}", f"{stats['purchases']['total_sum']:,.0f} â‚½")
    col2.metric("ĞŸÑ€Ğ¾Ğ´Ğ°Ğ¶Ğ¸", f"{stats['sales']['count']:,}", f"{stats['sales']['total_sum']:,.0f} â‚½")
    col3.metric("ĞĞ¾Ğ¼ĞµĞ½ĞºĞ»Ğ°Ñ‚ÑƒÑ€Ğ°", f"{stats['nomenclature_count']:,}")
    col4.metric("ĞšĞ»Ğ¸ĞµĞ½Ñ‚Ñ‹", f"{stats['clients_count']:,}")
    
    st.divider()
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ğŸ“Š Ğ—Ğ°ĞºÑƒĞ¿ĞºĞ¸ Ğ¿Ğ¾ Ğ¼ĞµÑÑÑ†Ğ°Ğ¼")
        purchases = load_purchases(str(date_from), str(date_to))
        if not purchases.empty:
            purchases['ĞœĞµÑÑÑ†'] = pd.to_datetime(purchases['Ğ”Ğ°Ñ‚Ğ°']).dt.to_period('M').astype(str)
            by_month = purchases.groupby('ĞœĞµÑÑÑ†')['Ğ¡ÑƒĞ¼Ğ¼Ğ°'].sum().reset_index()
            fig = px.bar(by_month, x='ĞœĞµÑÑÑ†', y='Ğ¡ÑƒĞ¼Ğ¼Ğ°')
            st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        st.subheader("ğŸ’° ĞŸÑ€Ğ¾Ğ´Ğ°Ğ¶Ğ¸ Ğ¿Ğ¾ Ğ¼ĞµÑÑÑ†Ğ°Ğ¼")
        sales = load_sales(str(date_from), str(date_to))
        if not sales.empty:
            real = sales[sales['Ğ¢Ğ¸Ğ¿'] == 'Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ']
            if not real.empty:
                real = real.copy()
                real['ĞœĞµÑÑÑ†'] = pd.to_datetime(real['Ğ”Ğ°Ñ‚Ğ°']).dt.to_period('M').astype(str)
                by_month = real.groupby('ĞœĞµÑÑÑ†')['Ğ¡ÑƒĞ¼Ğ¼Ğ°'].sum().reset_index()
                fig = px.bar(by_month, x='ĞœĞµÑÑÑ†', y='Ğ¡ÑƒĞ¼Ğ¼Ğ°')
                st.plotly_chart(fig, use_container_width=True)


# ============================================================
# MAIN
# ============================================================

def main():
    st.title("ğŸª ĞĞ½Ğ°Ğ»Ğ¸Ñ‚Ğ¸ĞºĞ° | ĞšĞ¾Ğ½Ğ´Ğ¸Ñ‚ĞµÑ€ÑĞºĞ°Ñ ĞŸÑ€Ğ¾Ñ…Ğ¾Ñ€Ğ¾Ğ²Ğ°")
    st.caption("Ğ”Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¸Ğ· 1Ğ¡:ĞšĞ¾Ğ¼Ğ¿Ğ»ĞµĞºÑĞ½Ğ°Ñ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ 2.5")
    
    try:
        stats = get_db_stats()
    except Exception as e:
        st.error(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ñ Ğº Ğ‘Ğ”: {e}")
        return
    
    with st.sidebar:
        st.header("ğŸ“… ĞŸĞµÑ€Ğ¸Ğ¾Ğ´")
        
        today = datetime.now().date()
        min_dates = [stats['purchases']['min_date'], stats['sales']['min_date']]
        max_dates = [stats['purchases']['max_date'], stats['sales']['max_date']]
        
        min_date = min([d for d in min_dates if d], default=today - timedelta(days=365))
        max_date = max([d for d in max_dates if d], default=today)
        
        if min_date > max_date:
            min_date, max_date = max_date, min_date
        
        default_from = max(min_date, max_date - timedelta(days=365))
        
        col1, col2 = st.columns(2)
        with col1:
            date_from = st.date_input("Ğ¡", value=default_from, min_value=min_date, max_value=max_date)
        with col2:
            date_to = st.date_input("ĞŸĞ¾", value=max_date, min_value=min_date, max_value=max_date)
        
        st.divider()
        
        if st.button("ğŸ”„ ĞĞ±Ğ½Ğ¾Ğ²Ğ¸Ñ‚ÑŒ", use_container_width=True):
            st.cache_data.clear()
            st.rerun()
    
    page = st.radio("Ğ Ğ°Ğ·Ğ´ĞµĞ»", ["ğŸ“ˆ Ğ¡Ğ²Ğ¾Ğ´ĞºĞ°", "ğŸ›’ Ğ—Ğ°ĞºÑƒĞ¿ĞºĞ¸", "ğŸ’° ĞŸÑ€Ğ¾Ğ´Ğ°Ğ¶Ğ¸", "ğŸ“¦ ĞĞ¾Ğ¼ĞµĞ½ĞºĞ»Ğ°Ñ‚ÑƒÑ€Ğ°"],
                    horizontal=True, label_visibility="collapsed")
    
    st.divider()
    
    if page == "ğŸ“ˆ Ğ¡Ğ²Ğ¾Ğ´ĞºĞ°":
        page_summary(date_from, date_to)
    elif page == "ğŸ›’ Ğ—Ğ°ĞºÑƒĞ¿ĞºĞ¸":
        page_purchases(date_from, date_to)
    elif page == "ğŸ’° ĞŸÑ€Ğ¾Ğ´Ğ°Ğ¶Ğ¸":
        page_sales(date_from, date_to)
    elif page == "ğŸ“¦ ĞĞ¾Ğ¼ĞµĞ½ĞºĞ»Ğ°Ñ‚ÑƒÑ€Ğ°":
        page_nomenclature()


if __name__ == "__main__":
    main()






















